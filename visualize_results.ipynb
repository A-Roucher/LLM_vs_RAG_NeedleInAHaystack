{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/results_gpt_rag.json', 'r') as file:\n",
    "    results = json.load(file)\n",
    "\n",
    "result_rag = pd.DataFrame(results)\n",
    "result_rag = result_rag.loc[result_rag['version'].isin([3, 4])]\n",
    "result_rag['score'] = result_rag['score'].apply(lambda x: (0 if x<5 else x)) / 10\n",
    "series_rag = result_rag.groupby(\"context_length\")['score'].mean()\n",
    "series_rag = pd.DataFrame(series_rag).rename(columns={'score': 'average_score'}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_long_context = pd.read_csv('original_results/gpt4.csv', index_col=0) / 10\n",
    "series_long_context=table_long_context.mean(axis=0)\n",
    "series_long_context = pd.DataFrame(series_long_context).rename(columns={'score': 'average_score'}).T\n",
    "series_long_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = pd.concat([series_long_context, series_rag], axis=0).T\n",
    "comb.columns = ['Long Context', 'RAG']\n",
    "\n",
    "comb = pd.DataFrame(comb.unstack().reset_index())\n",
    "comb.columns = ['model', 'context_length', 'average_score']\n",
    "\n",
    "comb['context_length'] = comb['context_length'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = px.scatter(comb, color=\"model\", x='context_length', y='average_score', title='Accuracy of Retrieval - RAG vs Long-Context GPT4', width=1000)\n",
    "fig2 = px.line(comb, color=\"model\", x='context_length', y='average_score', title='Accuracy of Retrieval - RAG vs Long-Context GPT4', width=1000).add_traces(fig1.data)\n",
    "\n",
    "\n",
    "fig2.update_layout(yaxis_range=[0.6, 1.05])\n",
    "fig2.update_layout(xaxis=dict(range=[0,130000]), yaxis_tickformat=',.0%', font=dict(\n",
    "        family=\"Arial\",\n",
    "        size=18,\n",
    "        color=\"grey\"\n",
    "    ))\n",
    "fig2.update_xaxes(tickvals = list(range(10000, 131000, 10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
